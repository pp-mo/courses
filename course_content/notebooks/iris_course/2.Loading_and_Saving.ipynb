{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Iris Cube\n",
    "\n",
    "**Learning Outcome**: by the end of this section, you will be able to use Iris to load datasets from disk as Iris cubes and save Iris cubes back to disk.\n",
    "\n",
    "**Duration:** 1 hour\n",
    "\n",
    "**Overview:**<br>\n",
    "2.1 [Iris Load Functions](#iris_load_functions)<br>\n",
    "2.2 [Saving Cubes](#saving)<br>\n",
    "2.3 [Out-of-core Processing](#out_of_core_processing)<br>\n",
    "2.5 [Exercise](#iris_cube_exercise)<br>\n",
    "2.6 [Summary of the Section](#iris_cube_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 2.1 Iris Load Functions<a id='iris_load_functions'></a>\n",
    "\n",
    "There are three main load functions in Iris: ``load``, ``load_cube`` and ``load_cubes``.\n",
    "\n",
    "1. **load** is a general purpose loading function. Typically this is where all data analysis will start, before more loading is refined with the more controlled loading from the other two functions.\n",
    "2. **load_cube** returns a single cube from the given source(s) and constraint. There will be exactly one cube, or an exception will be raised.\n",
    "3. **load_cubes** returns a list of cubes from the given sources(s) and constraint(s). There will be exactly one cube per constraint, or an exception will be raised.\n",
    "\n",
    "\n",
    "Note: ``load_cube`` is a special case of ``load``, which can be seen with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = iris.sample_data_path('air_temp.pp')\n",
    "c1, = iris.load(fname)\n",
    "c2 = iris.load_cube(fname)\n",
    "c1 == c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 2.2 Saving Cubes<a id='saving'></a>\n",
    "\n",
    "The [iris.save](https://scitools.org.uk/iris/docs/latest/iris/iris.html#iris.save) function provides a convenient interface to save Cube and CubeList instances.\n",
    "\n",
    "Below we load the `uk_hires.pp` file from Iris' provided sample data which returns a cubelist of the cubes that were produced from that file. We then save this cubelist out to netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = iris.sample_data_path('uk_hires.pp')\n",
    "cubes = iris.load(fname)\n",
    "iris.save(cubes, 'saved_cubes.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the ncdump to see what Iris saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h saved_cubes.nc | head -n 20\n",
    "!rm saved_cubes.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra keywords can be passed to specific fileformat savers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Suggested Activity: </b>Take a look at the above `iris.save` to see what fileformats iris supports saving to.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 2.3 Out-of-core Processing<a id='out_of_core_processing'></a>\n",
    "\n",
    "[Out-of-core processing](https://en.wikipedia.org/wiki/External_memory_algorithm) is a technical term that describes being able to process datasets that are too large to fit in memory at once. In Iris, this functionality is referred to as **lazy data**. It means that you can use Iris to load, process and save datasets that are too large to fit in memory without running out of memory. This is achieved by loading only the dataset's metadata and not the data array, unless this is specifically requested.\n",
    "\n",
    "To determine whether your cube has lazy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = iris.sample_data_path('air_temp.pp')\n",
    "cube = iris.load_cube(fname)\n",
    "print(cube.has_lazy_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris tries to maintain lazy data as much as possible. We refer to the operation of loading a cube's lazy data as 'realising' the cube's data. A cube's lazy data will only be loaded in a limited number of cases, including:\n",
    "\n",
    "* when the user directly requests the cube's data using `cube.data`,\n",
    "* when there is no lazy data processing algorithm available to perform the requested data processing, such as for peak finding, and\n",
    "* where actual data values are necessary, such as for cube plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.data\n",
    "print(cube.has_lazy_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 2.4 Exercise 2<a id='loading_exercise'></a>\n",
    "\n",
    "1\\. Load the file in `iris.sample_data_path('atlantic_profiles.nc')` as in exercise 1, but this time use `iris.load_cube` to load in the `sea_water_potential_temperature` cube only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Check whether this cube has lazy data? Print the minimum, maximum, mean and standard deviation of the cube's data. Does the cube still have lazy data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Go to the Iris reference documentation for ``iris.save``. What fileformats can Iris currently save to? What keywords are accepted to ``iris.save`` when saving a PP file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Solutions: \n",
    "Once you are happy with your answers, you can check the solutions by runnning the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ../../solutions/iris_exercise_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 2.5 Summary of the Section: Loading and Saving<a id='summary'></a>\n",
    "\n",
    "In this section we learnt:\n",
    "* Something"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
